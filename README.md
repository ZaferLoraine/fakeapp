# ğŸ› ï¸ FakeStore Data Pipeline

Este projeto realiza a extraÃ§Ã£o, transformaÃ§Ã£o e carga (ETL) de dados da FakeStore API utilizando **PySpark** e grava o resultado processado em um banco de dados **PostgreSQL** via JDBC.

---

##  Objetivo

- Coletar dados da FakeStore API.
- Limpar e tratar os dados (remover nulos e outliers).
- Aplicar filtros de negÃ³cio (ex: preÃ§o mÃ­nimo e avaliaÃ§Ã£o).
- Gerar resumos estatÃ­sticos por categoria de produto.
- Persistir os dados transformados em um banco de dados PostgreSQL.

---

##  Estrutura do Projeto

```text
.
â”œâ”€â”€ main.py                       # Script principal (pipeline completo)
â”œâ”€â”€ processamento.py              # Classe com a lÃ³gica de ETL (FakeStoreDataProcessor)
â”œâ”€â”€ coleta.py                     # FunÃ§Ã£o para coletar dados da API
â”œâ”€â”€ schema.py                     # Schema do DataFrame Spark
â”œâ”€â”€ requirements.txt              # DependÃªncias do projeto (PySpark, SQLAlchemy etc.)
â””â”€â”€ README.md                     # Este arquivo
